{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from algorithms.selection import skey, get_topk, get_candidates_with_label, tripet_greedy, nn_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = np.array(pickle.load(open(\"data/bm_triplets/3c2_unique=182/train_triplets.pkl\", \"rb\")))\n",
    "embeds = pickle.load(open(\"embeds/bm/human/MTL.BCETN_train_emb10.pkl\", \"rb\"))\n",
    "labels = pickle.load(open(\"/net/scratch/hanliu-shared/data/bm/embs/dwac_train_emb10.merged10.pkl\", \"rb\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 11, 17, 25, 26, 34, 56, 62, 95, 103), 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripet_greedy(embeds, 10, triplets, labels=labels, topk=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 669920)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpips_d_matrix = pickle.load(open(\"embeds/lpips/lpips.bm.train.pkl\", \"rb\"))\n",
    "lpips_triplets = pickle.load(open(\"data/bm_lpips_triplets/train_triplets.pkl\", \"rb\"))\n",
    "len(lpips_d_matrix), len(lpips_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 23, 33, 92, 99, 104, 106, 113, 131, 153), 11872)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripet_greedy(embeds, 10, lpips_d_matrix, labels=labels, topk=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 73, 75, 78, 79, 121, 126, 130, 146, 153), 7691)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripet_greedy(embeds, 10, lpips_triplets, labels=labels, topk=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.tensor(embeds)\n",
    "dist = torch.cdist(z, z).numpy()\n",
    "uni = np.unique(triplets)\n",
    "n = len(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "scores = defaultdict(lambda: 0)\n",
    "visits = defaultdict(lambda: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in triplets:\n",
    "    a, p, n = t\n",
    "    key = skey([p, n])\n",
    "    if dist[a, p] <= dist[a, n]:      \n",
    "        scores[key] += 1\n",
    "    visits[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 95) 2.0000 10\n",
      "(56, 95, 103) 8.0000 10\n",
      "(3, 56, 95, 103) 17.0000 10\n",
      "(3, 34, 56, 95, 103) 21.0000 10\n",
      "(3, 11, 34, 56, 95, 103) 24.0000 10\n",
      "(3, 17, 25, 34, 56, 95, 103) 30.0000 10\n",
      "(3, 11, 17, 25, 34, 56, 95, 103) 35.0000 10\n",
      "(3, 11, 13, 17, 25, 34, 56, 95, 103) 37.0000 10\n",
      "(3, 11, 17, 25, 26, 34, 56, 62, 95, 103) 41.0000 10\n"
     ]
    }
   ],
   "source": [
    "m = 10\n",
    "topk = 10\n",
    "curr_scores = deepcopy(scores)\n",
    "curr_visits = deepcopy(visits)\n",
    "if labels is not None:\n",
    "    cand_scores, cand_visits = get_candidates_with_label(scores, visits, labels)\n",
    "    beam, w = get_topk(cand_scores, cand_visits, topk, metric=\"count\", verbose=True)\n",
    "else:\n",
    "    beam, w = get_topk(curr_scores, curr_visits, topk, metric=\"count\", verbose=True)\n",
    "for i in range(3, m+1):\n",
    "    new_scores = defaultdict(lambda: 0)\n",
    "    new_visits = deepcopy(new_scores)\n",
    "    for b in beam:\n",
    "        for k in uni:\n",
    "            if k not in b:\n",
    "                key = skey(b + (k,))\n",
    "                base_score = new_scores[key]\n",
    "                base_visit = new_visits[key]\n",
    "                if base_score == 0 and curr_scores[b] > 0:\n",
    "                    new_scores[key] += curr_scores[b]\n",
    "                if base_visit == 0 and curr_visits[b] > 0:\n",
    "                    new_visits[key] += curr_visits[b]\n",
    "                for j in b:\n",
    "                    new_scores[key] += scores[skey([j, k])]\n",
    "                    new_visits[key] += visits[skey([j, k])]\n",
    "    curr_scores = new_scores\n",
    "    curr_visits = new_visits\n",
    "    beam, w = get_topk(curr_scores, curr_visits, topk, metric=\"count\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1NN Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pickle.load(open(\"/net/scratch/hanliu-shared/data/bm/embs/dwac_train_emb10.merged10.pkl\", \"rb\"))[2]\n",
    "y_valid = pickle.load(open(\"/net/scratch/hanliu-shared/data/bm/embs/dwac_valid_emb10.merged10.pkl\", \"rb\"))[2]\n",
    "train = pickle.load(open(\"embeds/bm/human/MTL.BCETN_train_emb10.pkl\", \"rb\"))\n",
    "valid = pickle.load(open(\"embeds/bm/human/MTL.BCETN_valid_emb10.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 12, 19, 21, 23, 26, 30, 33, 50, 143), 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_greedy((train, valid), 10, (y_train, y_valid), topk=10, metric=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt = torch.tensor(train)\n",
    "zv = torch.tensor(valid)\n",
    "dist = torch.cdist(zt, zv).numpy()\n",
    "y1, y2 = y_train, y_valid\n",
    "uni = np.arange(len(dist))\n",
    "n = len(uni)\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "scores = defaultdict(lambda: 0)\n",
    "nearns = defaultdict(lambda: np.zeros(n, dtype=np.int8) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "for c in combinations(range(n), 2):\n",
    "    key = skey(c)\n",
    "    dsx = dist[key, :]\n",
    "    nn1mask = np.argmin(dsx, axis=0)\n",
    "    nn1 = np.take(key, nn1mask)\n",
    "    nn1pred = np.take(y1, nn1)\n",
    "    score = (nn1pred == y2).sum()\n",
    "    scores[key] = score\n",
    "    nearns[key] = nn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 143) 1.0000 100\n",
      "(1, 50, 143) 1.0000 100\n",
      "(1, 12, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 21, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 21, 23, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 21, 23, 26, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 21, 23, 26, 30, 50, 143) 1.0000 100\n",
      "(1, 12, 19, 21, 23, 26, 30, 33, 50, 143) 1.0000 100\n"
     ]
    }
   ],
   "source": [
    "m = 10\n",
    "topk = 100\n",
    "curr_scores = deepcopy(scores)\n",
    "# curr_nearns = deepcopy(nearns)\n",
    "beam, w = get_topk(curr_scores, defaultdict(lambda: len(y2)), topk, metric=\"acc\", verbose=True)\n",
    "for _ in range(3, m+1):\n",
    "    new_scores = defaultdict(lambda: 0)\n",
    "    # new_nearns = deepcopy(new_scores)\n",
    "    for b in beam:\n",
    "        for k in uni:\n",
    "            if k not in b:\n",
    "                key = skey(b + (k,))\n",
    "                dsx = dist[key, :]\n",
    "                nn1mask = np.argmin(dsx, axis=0)\n",
    "                nn1 = np.take(key, nn1mask)\n",
    "                nn1pred = np.take(y1, nn1)\n",
    "                score = (nn1pred == y2).sum()\n",
    "                new_scores[key] = score\n",
    "                # new_nearns[key] = nn1\n",
    "    curr_scores = new_scores\n",
    "    # curr_nearns = new_nearns\n",
    "    beam, w = get_topk(curr_scores, defaultdict(lambda: len(y2)), topk, metric=\"acc\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(y_train, beam[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63211ff5f667d2462bf3cbef4ab188efe8fd5838e9505b6620d21c1e36f41af8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
