{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from lime.submodular_pick import SubmodularPick\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def extract_W_multiclass(coef, xs, ys, coo=True):\n",
    "    W = [{} for _ in xs]\n",
    "    features = (xs.tocoo().row, xs.tocoo().col) if coo else np.where(xs != None)\n",
    "    for (r, c) in zip(features[0], features[1]):\n",
    "        W[r][c] = coef[ys[r]][c]\n",
    "    return W\n",
    "\n",
    "def get_feature_importance(W):\n",
    "    importance = {}\n",
    "    for ins in W:\n",
    "        for j in ins:\n",
    "            importance[j] = importance.get(j, 0.0) + np.abs(ins[j])\n",
    "    for j in importance:\n",
    "        importance[j] = np.sqrt(importance[j])\n",
    "    return importance\n",
    "\n",
    "def get_used(feature_dict, top=10):\n",
    "    # only consider top 10 features as used\n",
    "    values = [(np.abs(v), k) for k, v in feature_dict.items()]\n",
    "    values.sort(reverse=True)\n",
    "    return [i for _, i in values[:top]]\n",
    "\n",
    "def lime_objective(results, W, importance, top=10):\n",
    "    obj, covered = 0, set()\n",
    "    for index in results:\n",
    "        for j in get_used(W[index], top):\n",
    "            if j not in covered:\n",
    "                obj += importance[j]\n",
    "                covered.add(j)\n",
    "    return obj, covered\n",
    "\n",
    "def greedy_sp_search_multiclass(results, W, importance, budget, ys, top=10):\n",
    "    flattened = [index for _class in results for index in _class]\n",
    "    class_len = list(map(len, results))\n",
    "    obj, covered = lime_objective(flattened, W, importance, top)\n",
    "    max_diff, max_index = -1, -1\n",
    "    for i in range(len(W)):\n",
    "        if i in flattened or class_len[ys[i]] >= budget[ys[i]]:\n",
    "            continue\n",
    "        diff = 0\n",
    "        for j in get_used(W[i], top):\n",
    "            if j not in covered:\n",
    "                diff += importance[j]\n",
    "        if diff > max_diff:\n",
    "            max_diff, max_index = diff, i\n",
    "    return max_index, obj\n",
    "\n",
    "def gready_sp_multiclass(W, budget, ys, top=10):\n",
    "    importance = get_feature_importance(W)\n",
    "    results = [[] for _ in range(np.unique(ys).size)]\n",
    "    while np.any(list(map(len, results)) < np.array(budget)):\n",
    "        max_index, current_obj = greedy_sp_search_multiclass(results, W, importance, budget, ys, top)\n",
    "        if max_index >= 0:\n",
    "            results[ys[max_index]].append(max_index)\n",
    "#             print(max_index)\n",
    "        else:\n",
    "            break\n",
    "    return results, current_obj, importance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "K=5\n",
    "w_e = np.array([0.11010821, 0.1750904, 0, 0, 0, 0.5072202 , 0.20758119, 0])\n",
    "\n",
    "fids, inputs, labels, embeds, preds = pickle.load(open('data/prostatex/train_findings_emb10.pkl', \"rb\"))\n",
    "X_train = embeds\n",
    "y_train = labels\n",
    "p_train = preds\n",
    "f_train = fids\n",
    "\n",
    "fids, inputs, labels, embeds, preds = pickle.load(open('data/prostatex/valid_findings_emb10.pkl', \"rb\"))\n",
    "X_valid = embeds\n",
    "y_valid = labels\n",
    "p_valid = preds\n",
    "f_valid = fids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "full = KNeighborsClassifier(n_neighbors=K)\n",
    "full.fit(X_train, y_train)\n",
    "full.score(X_valid, y_valid)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6020408163265306"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.random.seed(42)\n",
    "scores = []\n",
    "for i in range(100):\n",
    "    index = np.random.choice(range(len(X_train)), 20)\n",
    "    rand = KNeighborsClassifier(n_neighbors=K)\n",
    "    rand.fit(X_train[index], y_train[index])\n",
    "    scores.append(rand.score(X_valid, y_valid))\n",
    "np.mean(scores), np.std(scores)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5691836734693877, 0.08757194935614838)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "protodash = ProtodashExplainer()\n",
    "_, index, _ = protodash.explain(X_train, X_train, m=20)\n",
    "proto = KNeighborsClassifier(n_neighbors=K)\n",
    "proto.fit(X_train[index], y_train[index])\n",
    "proto.score(X_valid, y_valid)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.47959183673469385"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "# explainer = LimeTabularExplainer(X_train)\n",
    "# splime = SubmodularPick(explainer, X_train, lr.predict_proba, method='full', num_features=10, num_exps_desired=5)\n",
    "coef = np.vstack([lr.coef_, -lr.coef_])\n",
    "W = extract_W_multiclass(coef, X_train, y_train, coo=False)\n",
    "budget = [10] * 2\n",
    "sp_results, current_obj, importance = gready_sp_multiclass(W, budget, y_train, 100)\n",
    "index = sp_results[0] + sp_results[1]\n",
    "splime = KNeighborsClassifier(n_neighbors=K)\n",
    "splime.fit(X_train, y_train)\n",
    "splime.score(X_valid, y_valid)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6020408163265306"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('aix360': conda)"
  },
  "interpreter": {
   "hash": "aef7d833d8ea9caacc891989fe79337ec18920a218d900bba4c64cd373a7152d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}