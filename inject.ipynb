{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject = torchvision.transforms.functional.erase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import utils\n",
    "train_dir = \"/net/scratch/hanliu-shared/data/bm/train\"\n",
    "valid_dir = \"/net/scratch/hanliu-shared/data/bm/valid\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=utils.bm_transform())\n",
    "valid_dataset = torchvision.datasets.ImageFolder(valid_dir, transform=utils.bm_transform())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt, nv = len(train_dataset), len(valid_dataset)\n",
    "ist, isv = [10] * nt, [10]* nv\n",
    "ht, hv = [5] * nt, [5] * nv\n",
    "wt, wv = list(range(10, nt+10)), list(range(nt+10, nt+10 + nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = [], []\n",
    "for i, b in enumerate(train_dataset):\n",
    "    x, y = b\n",
    "    a = inject(x, ist[i], ist[i], ht[i], wt[i], v=0, inplace=False)\n",
    "    x_train.append(torchvision.transforms.functional.to_pil_image(a))\n",
    "for i, b in enumerate(valid_dataset):\n",
    "    x, y = b\n",
    "    a = inject(x, isv[i], isv[i], hv[i], wv[i], v=0, inplace=False)\n",
    "    x_valid.append(torchvision.transforms.functional.to_pil_image(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_dir = \"/net/scratch/hanliu-shared/data/bm/train_aug\"\n",
    "valid_aug_dir = \"/net/scratch/hanliu-shared/data/bm/valid_aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2p = []\n",
    "for root, _, fnames in sorted(os.walk(train_dir, followlinks=True)):\n",
    "    for fname in sorted(fnames):\n",
    "        path = os.path.join(root, fname)\n",
    "        if path[-4:] == \".pkl\":\n",
    "            continue\n",
    "        i2p.append(path.replace(\"train\", \"train_aug\"))\n",
    "i2p = {i:p for i, p in enumerate(i2p)}\n",
    "p2i = {v.split(\"/\")[-1]:k for k, v in i2p.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in i2p.items():\n",
    "    x_train[i].save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2p = []\n",
    "for root, _, fnames in sorted(os.walk(valid_dir, followlinks=True)):\n",
    "    for fname in sorted(fnames):\n",
    "        path = os.path.join(root, fname)\n",
    "        if path[-4:] == \".pkl\":\n",
    "            continue\n",
    "        i2p.append(path.replace(\"valid\", \"valid_aug\"))\n",
    "i2p = {i:p for i, p in enumerate(i2p)}\n",
    "p2i = {v.split(\"/\")[-1]:k for k, v in i2p.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in i2p.items():\n",
    "    x_valid[i].save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet = [h*w for h, w in zip(ht, wt)]\n",
    "sizev = [h*w for h, w in zip(hv, wv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt = np.array([[np.abs(sizet[i] - sizet[j]) for i in range(nt)] for j in range(nt)])\n",
    "dvv = np.array([[np.abs(sizev[i] - sizev[j]) for i in range(nv)] for j in range(nv)])\n",
    "dtv = np.array([[np.abs(sizev[i] - sizet[j]) for i in range(nv)] for j in range(nt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dtt, open(\"embeds/aug/aug.bm.train.pkl\", \"wb\"))\n",
    "pickle.dump(dvv, open(\"embeds/aug/aug.bm.valid.pkl\", \"wb\"))\n",
    "pickle.dump(dtv, open(\"embeds/aug/aug.bm.trxvl.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
